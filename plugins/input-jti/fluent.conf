# In v1 configuration, type and id are @ prefix parameters.
# @type and @id are recommended. type and id are still available for backward compatibility

## built-in TCP input
## $ echo <json> | fluent-cat <tag>

<source>
  @type forward
  @id forward_input
</source>

#################
## Input      ###
#################

########## Jvision ################
<source>
    @type udp
    tag jnpr.jvision
    format juniper_jti
    port {{ PORT_JTI }}
    bind 0.0.0.0
</source>

########## Analyticsd ################
<source>
    @type udp
    tag jnpr.analyticsd
    format juniper_analyticsd
    port {{ PORT_ANALYTICSD }}
    bind 0.0.0.0
</source>


#################
## Filters    ###
#################

#  Adding a filter example for future references
#
#  <filter jnpr.**>
#    @type record_transformer
#    enable_ruby
#    <record>
#      timestamp_utc ${Time.now.utc.strftime('%Y-%m-%dT%H:%M:%S.%9NZ')}
#    </record>
#  </filter>


#################
## Output     ###
#################

<match jnpr.**>
    type copy
{% if OUTPUT_STDOUT == 'true' %}
    <store>
        @type stdout
        @id stdout_output
        localtime
    </store>
{% endif %}
{% if OUTPUT_INFLUXDB == 'true' %}
    <store>
        type influxdb

        host "{{ INFLUXDB_ADDR }}"
        port "{{ INFLUXDB_PORT }}"
        dbname "{{ INFLUXDB_DB }}"
        user "{{ INFLUXDB_USER }}"
        password "{{ INFLUXDB_PWD }}"

        value_keys ["value"]
        ####
        buffer_type memory
        # buffer_chunk_limit 524288 # 512 * 1024
        # buffer_queue_limit 1024
        flush_interval "{{ INFLUXDB_FLUSH_INTERVAL }}"
        # retry_limit 17
        # retry_wait 1.0
        # num_threads 1
    </store>
{% endif %}

## TODO investigate forest plugin https://github.com/tagomoris/fluent-plugin-forest

{% if OUTPUT_KAFKA == 'true' %}
    <store>
      @type kafka

      # Brokers: you can choose either brokers or zookeeper.
      brokers               {{ KAFKA_ADDR }}:{{ KAFKA_PORT }}
      # zookeeper           <zookeeper_host>:<zookeeper_port> # Set brokers via Zookeeper

      default_topic         {{ KAFKA_TOPIC }}
      # default_partition_key (string)   :default => nil
      output_data_type      {{ KAFKA_DATA_TYPE }} # |ltsv|msgpack|attr:<record name>|<formatter name>)
      output_include_tag    true # |false) :default => false
      output_include_time   true # |false) :default => false

      # max_send_retries    (integer)    :default => 3
      # required_acks       (integer)    :default => 0
      # ack_timeout_ms      (integer)    :default => 1500
      compression_codec     {{ KAFKA_COMPRESSION_CODEC }} # (none|gzip|snappy) :default => none
    </store>
{% endif %}
</match>

# Listen HTTP for monitoring
# http://localhost:24220/api/plugins
# http://localhost:24220/api/plugins?type=TYPE
# http://localhost:24220/api/plugins?tag=MYTAG
<source>
  @type monitor_agent
  @id monitor_agent_input
  port 24220
</source>

# Listen DRb for debug
<source>
  @type debug_agent
  @id debug_agent_input
  bind 127.0.0.1
  port 24230
</source>

## match tag=debug.** and dump to console
<match debug.**>
  @type stdout
  @id stdout_output
</match>

# match fluent's internal events
<match fluent.**>
  @type stdout
</match>
