## built-in TCP input
## $ echo <json> | fluent-cat <tag>

<source>
  @type forward
  @id forward_input
</source>

#################
## Input      ###
#################

########## Jvision ################
<source>
    @type udp
    tag juniperNetworks
    format juniper_udp_native
    port 50000
    bind 0.0.0.0
    body_size_limit 5000
  </source>


########## Analyticsd ################
<source>
    @type udp
    tag jnpr.analyticsd
    format juniper_analyticsd
    message_length_limit 5000
    remove_newline false
    port {{ PORT_ANALYTICSD }}
    bind 0.0.0.0
</source>
<match juniperNetworks>
  @type rewrite_tag_filter
  rewriterule1 sensor_name (.+)  ${tag}.$1
</match>
<match jnpr.**>
    type copy
    <store>
        @type stdout
        @id stdout_output
        localtime
    </store>

{% if OUTPUT_INFLUXDB == 'true' %}
    <store>
        type influxdb

        host "{{ INFLUXDB_ADDR }}"
        port "{{ INFLUXDB_PORT }}"
        dbname "{{ INFLUXDB_DB }}"
        user "{{ INFLUXDB_USER }}"
        password "{{ INFLUXDB_PWD }}"
        auto_tags true
        #value_keys ["value"]
        ####
        buffer_type memory
        # buffer_chunk_limit 524288 # 512 * 1024
        # buffer_queue_limit 1024
        flush_interval "{{ INFLUXDB_FLUSH_INTERVAL }}"
        # retry_limit 17
        # retry_wait 1.0
        # num_threads 1
    </store>
{% endif %}
{% if OUTPUT_KAFKA == 'true' %}
    <store>
      @type kafka

      # Brokers: you can choose either brokers or zookeeper.
      brokers               {{ KAFKA_ADDR }}:{{ KAFKA_PORT }}
      # zookeeper           <zookeeper_host>:<zookeeper_port> # Set brokers via Zookeeper

      default_topic         {{ KAFKA_TOPIC }}
      # default_partition_key (string)   :default => nil
      output_data_type      {{ KAFKA_DATA_TYPE }} # |ltsv|msgpack|attr:<record name>|<formatter name>)
      output_include_tag    true # |false) :default => false
      output_include_time   true # |false) :default => false

      # max_send_retries    (integer)    :default => 3
      # required_acks       (integer)    :default => 0
      # ack_timeout_ms      (integer)    :default => 1500
      # compression_codec   (none|gzip|snappy) :default => none
    </store>
{% endif %}
</match>

#################
## Output     ###
#################

##### CPU #######

<match juniperNetworks.cpu_memory_util_ext>
    type copy
{% if OUTPUT_STDOUT == 'true' %}
    <store>
        @type stdout
        @id stdout_output
        localtime
    </store>
{% endif %}
{% if OUTPUT_INFLUXDB == 'true' %}
    <store>
        type influxdb

        host "{{ INFLUXDB_ADDR }}"
        port "{{ INFLUXDB_PORT }}"
        dbname "{{ INFLUXDB_DB }}"
        user "{{ INFLUXDB_USER }}"
        password "{{ INFLUXDB_PWD }}"
        time_precision ms
        tag_keys ["device","utilization.application_utilization.name","utilization.name"]
        tag_keys_field key_fields
        ####
        buffer_type memory
        # buffer_chunk_limit 524288 # 512 * 1024
        # buffer_queue_limit 1024
        flush_interval "{{ INFLUXDB_FLUSH_INTERVAL }}"
        # retry_limit 17
        # retry_wait 1.0
        # num_threads 1
    </store>
{% endif %}

## TODO investigate forest plugin https://github.com/tagomoris/fluent-plugin-forest

{% if OUTPUT_KAFKA == 'true' %}
    <store>
      @type kafka

      # Brokers: you can choose either brokers or zookeeper.
      brokers               {{ KAFKA_ADDR }}:{{ KAFKA_PORT }}
      # zookeeper           <zookeeper_host>:<zookeeper_port> # Set brokers via Zookeeper

      default_topic         {{ KAFKA_TOPIC }}
      # default_partition_key (string)   :default => nil
      output_data_type      {{ KAFKA_DATA_TYPE }} # |ltsv|msgpack|attr:<record name>|<formatter name>)
      output_include_tag    true # |false) :default => false
      output_include_time   true # |false) :default => false

      # max_send_retries    (integer)    :default => 3
      # required_acks       (integer)    :default => 0
      # ack_timeout_ms      (integer)    :default => 1500
      compression_codec     {{ KAFKA_COMPRESSION_CODEC }} # (none|gzip|snappy) :default => none
    </store>
{% endif %}
</match>

################ END CPU ################

############### PACKET STATS #############

<match juniperNetworks.jnpr_packet_statistics_ext>
    type copy
{% if OUTPUT_STDOUT == 'true' %}
    <store>
        @type stdout
        @id stdout_output
        localtime
    </store>
{% endif %}
{% if OUTPUT_INFLUXDB == 'true' %}
    <store>
        type influxdb
        host "{{ INFLUXDB_ADDR }}"
        port "{{ INFLUXDB_PORT }}"
        dbname "{{ INFLUXDB_DB }}"
        user "{{ INFLUXDB_USER }}"
        password "{{ INFLUXDB_PWD }}"
        time_precision ms
        tag_keys ["device","packet_stats.name"]
        tag_keys_field key_fields
        ####
        buffer_type memory
        # buffer_chunk_limit 524288 # 512 * 1024
        # buffer_queue_limit 1024
        flush_interval "{{ INFLUXDB_FLUSH_INTERVAL }}"
        # retry_limit 17
        # retry_wait 1.0
        # num_threads 1
    </store>
{% endif %}

## TODO investigate forest plugin https://github.com/tagomoris/fluent-plugin-forest

{% if OUTPUT_KAFKA == 'true' %}
    <store>
      @type kafka

      # Brokers: you can choose either brokers or zookeeper.
      brokers               {{ KAFKA_ADDR }}:{{ KAFKA_PORT }}
      # zookeeper           <zookeeper_host>:<zookeeper_port> # Set brokers via Zookeeper

      default_topic         {{ KAFKA_TOPIC }}
      # default_partition_key (string)   :default => nil
      output_data_type      {{ KAFKA_DATA_TYPE }} # |ltsv|msgpack|attr:<record name>|<formatter name>)
      output_include_tag    true # |false) :default => false
      output_include_time   true # |false) :default => false

      # max_send_retries    (integer)    :default => 3
      # required_acks       (integer)    :default => 0
      # ack_timeout_ms      (integer)    :default => 1500
      compression_codec     {{ KAFKA_COMPRESSION_CODEC }} # (none|gzip|snappy) :default => none
    </store>
{% endif %}
</match>

############### END PACKETS STATS #########

############### LSP STATS #################

<match juniperNetworks.jnpr_lsp_statistics_ext>
    type copy
{% if OUTPUT_STDOUT == 'true' %}
    <store>
        @type stdout
        @id stdout_output
        localtime
    </store>
{% endif %}
{% if OUTPUT_INFLUXDB == 'true' %}
    <store>
        type influxdb
        host "{{ INFLUXDB_ADDR }}"
        port "{{ INFLUXDB_PORT }}"
        dbname "{{ INFLUXDB_DB }}"
        user "{{ INFLUXDB_USER }}"
        password "{{ INFLUXDB_PWD }}"
        time_precision ms
        tag_keys ["device","lsp_stats_records.name"]
        tag_keys_field key_fields
        ####
        buffer_type memory
        # buffer_chunk_limit 524288 # 512 * 1024
        # buffer_queue_limit 1024
        flush_interval "{{ INFLUXDB_FLUSH_INTERVAL }}"
        # retry_limit 17
        # retry_wait 1.0
        # num_threads 1
    </store>
{% endif %}

## TODO investigate forest plugin https://github.com/tagomoris/fluent-plugin-forest

{% if OUTPUT_KAFKA == 'true' %}
    <store>
      @type kafka

      # Brokers: you can choose either brokers or zookeeper.
      brokers               {{ KAFKA_ADDR }}:{{ KAFKA_PORT }}
      # zookeeper           <zookeeper_host>:<zookeeper_port> # Set brokers via Zookeeper

      default_topic         {{ KAFKA_TOPIC }}
      # default_partition_key (string)   :default => nil
      output_data_type      {{ KAFKA_DATA_TYPE }} # |ltsv|msgpack|attr:<record name>|<formatter name>)
      output_include_tag    true # |false) :default => false
      output_include_time   true # |false) :default => false

      # max_send_retries    (integer)    :default => 3
      # required_acks       (integer)    :default => 0
      # ack_timeout_ms      (integer)    :default => 1500
      compression_codec     {{ KAFKA_COMPRESSION_CODEC }} # (none|gzip|snappy) :default => none
    </store>
{% endif %}
</match>

############### END LSP STATS #############


################## ALL #############
<match juniperNetworks.**>
    type copy
{% if OUTPUT_STDOUT == 'true' %}
    <store>
        @type stdout
        @id stdout_output
        localtime
    </store>
{% endif %}
{% if OUTPUT_INFLUXDB == 'true' %}
    <store>
        type influxdb

        host "{{ INFLUXDB_ADDR }}"
        port "{{ INFLUXDB_PORT }}"
        dbname "{{ INFLUXDB_DB }}"
        user "{{ INFLUXDB_USER }}"
        password "{{ INFLUXDB_PWD }}"
        time_precision ms
        tag_keys ["device"]
        tag_keys_field key_fields
        ####
        buffer_type memory
        # buffer_chunk_limit 524288 # 512 * 1024
        # buffer_queue_limit 1024
        flush_interval "{{ INFLUXDB_FLUSH_INTERVAL }}"
        # retry_limit 17
        # retry_wait 1.0
        # num_threads 1
    </store>
{% endif %}

## TODO investigate forest plugin https://github.com/tagomoris/fluent-plugin-forest

{% if OUTPUT_KAFKA == 'true' %}
    <store>
      @type kafka

      # Brokers: you can choose either brokers or zookeeper.
      brokers               {{ KAFKA_ADDR }}:{{ KAFKA_PORT }}
      # zookeeper           <zookeeper_host>:<zookeeper_port> # Set brokers via Zookeeper

      default_topic         {{ KAFKA_TOPIC }}
      # default_partition_key (string)   :default => nil
      output_data_type      {{ KAFKA_DATA_TYPE }} # |ltsv|msgpack|attr:<record name>|<formatter name>)
      output_include_tag    true # |false) :default => false
      output_include_time   true # |false) :default => false

      # max_send_retries    (integer)    :default => 3
      # required_acks       (integer)    :default => 0
      # ack_timeout_ms      (integer)    :default => 1500
      compression_codec     {{ KAFKA_COMPRESSION_CODEC }} # (none|gzip|snappy) :default => none
    </store>
{% endif %}
</match>

########################### END INTERFACE #############################

# Listen HTTP for monitoring
# http://localhost:24220/api/plugins
# http://localhost:24220/api/plugins?type=TYPE
# http://localhost:24220/api/plugins?tag=MYTAG
<source>
  @type monitor_agent
  @id monitor_agent_input
  port 24220
</source>

# Listen DRb for debug
<source>
  @type debug_agent
  @id debug_agent_input
  bind 127.0.0.1
  port 24230
</source>

## match tag=debug.** and dump to console
<match debug.**>
  @type stdout
  @id stdout_output
</match>

# match fluent's internal events
<match fluent.**>
  @type stdout
</match>



